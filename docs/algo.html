<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Hyfe CoughMonitor Suite (CMS) V3+ Evidence Dossier</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="../style.css" />
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="shortcut icon" href="/favicon.ico">

</head>
<body>
<header id="title-block-header">
<h1 class="title">Hyfe CoughMonitor Suite (CMS) V3+ Evidence
Dossier</h1>
</header>
<h1 id="algorithm-development-principles-and-practice">Algorithm
Development: Principles and Practice</h1>
<p>This document describes the principles, processes, and best practices
used in the development of the Hyfe cough detection algorithm.</p>
<h2 id="overview-of-the-hyfe-cough-detection-algorithm">Overview of the
Hyfe Cough Detection Algorithm</h2>
<p>The Hyfe cough detection algorithm is an on-device machine learning
system that runs on a wrist-worn smartwatch. Its purpose is to detect
cough events from a stream of real-time, continuous audio, and generate
corresponding timestamps. The algorithm is optimized for:</p>
<ul>
<li>Near-field, user-originating coughs<br />
</li>
<li>Real-time execution on a low-power embedded system<br />
</li>
<li>High specificity in real-world contexts with moderate background
noise<br />
</li>
<li>Privacy-by-design (no audio storage or transmission)</li>
</ul>
<p>The system continuously acquires audio from an onboard microphone,
and then processes that audio through a two-step algorithm (first, a
lightweight feature-extraction pipeline for the identification of
onset/explosive events; second, an ML classifier which categorizes
events as cough or non-cough) and, when a cough signature is detected,
stores a timestamp locally.</p>
<h2 id="principles-guiding-algorithm-development">Principles Guiding
Algorithm Development</h2>
<p>Though not a medical device, the algorithm development process
followed well-established machine learning and medical device software
practices:</p>
<ul>
<li>Use of high-quality, adjudicated labels<br />
</li>
<li>Clear separation of training and test datasets<br />
</li>
<li>Diverse, representative data from real-world conditions<br />
</li>
<li>Privacy-first design, minimizing sensitive data exposure<br />
</li>
<li>Embedded ML design constraints, ensuring reliability under limited
memory and compute<br />
</li>
<li>Controls for noise, drift, and ambiguous audio<br />
</li>
<li>Reproducible pipelines and documented SOPs</li>
</ul>
<h2 id="dataset-composition-and-data-provenance">Dataset Composition and
Data Provenance</h2>
<p>Algorithm development requires a large collection of raw acoustic
data representing both coughs and non-cough events and contexts across a
variety of environmental and physiological contexts. The
training/development dataset consists of continuous audio recordings
collected from individuals wearing/using an audio capture device (the
ID206 device itself; phones; third-party wrist-worn audio recorders) in
both real-world and controlled settings. Data sources included:</p>
<ul>
<li>Daily-living soundscapes (homes, workplaces, outdoors)<br />
</li>
<li>Multiple cough etiologies (e.g., chronic, acute, asthma-associated
coughs)<br />
</li>
<li>Wide variability in background noise<br />
</li>
<li>Demographic diversity across age and health conditions<br />
</li>
<li>Diversity in devices and modality (wearing, desktop, bedside,
etc.)</li>
</ul>
<p>Strict controls governed data provenance:</p>
<ul>
<li>Audio was uploaded to secure, encrypted systems.<br />
</li>
<li>All recordings were de-identified and segmented into 1-minute
chunks.<br />
</li>
<li>Access to raw audio was restricted to trained annotators.<br />
</li>
<li>All annotations were logged, versioned, and traceable.<br />
</li>
<li>The labels dataset was curated such that only well-annotated,
near-field, unambiguous coughs were included in the final training
set.</li>
</ul>
<p>High-quality labels are critical, as the algorithm’s performance
depends directly on the accuracy and consistency of ground truth.
Accordingly, the generation of labels is governed by a rigorous
multi-step process:</p>
<ul>
<li>Two independent labelers annotated each 1-minute audio
segment.<br />
</li>
<li>Labelers used spectrograms and waveforms to visually inspect
acoustic events.<br />
</li>
<li>Each segment was evaluated for coughs, throat clears, sneezes,
crying, and ambiguous cases.<br />
</li>
<li>Events could include “far” or “not sure” tags to flag
uncertainty.<br />
</li>
<li>Disagreements triggered adjudication by an expert reviewer
(MD/PhD).</li>
</ul>
<h2 id="traintest-split">Train/test split</h2>
<p>The dataset used for algorithm training was partitioned using best
practices that prevent overfitting and ensure generalization:</p>
<ul>
<li>Training set – used to learn model parameters<br />
</li>
<li>Validation set – used for tuning and internal evaluation<br />
</li>
<li>Hold-out test set – kept fully independent and untouched during
development</li>
</ul>
<p>The classifier training dataset consisted of over 500,000 snippets
derived from the labeling process. Ambiguous or low-confidence labels
(ie, those labeled as “far” or “not sure”) were excluded entirely from
training, reducing the risk of label noise affecting model performance.
In testing, they were included, and accuracy statistics were computed
for both their inclusion and exclusion.</p>
<p>The “holdout” dataset consists of data with the following
characteristics and provenance:</p>
<ul>
<li>ID206: 1545 coughs and 544.2 minutes of non-cough sounds.<br />
</li>
<li>Domino watch (a deprecated wrist-worn device used by Hyfe with audio
collected at 44.1khz and downsampled to the ID206’s 8khz rate): 248
coughs and 503.8 minutes of non-cough sounds.<br />
</li>
<li>Phone: 715 coughs and 348.5 minutes of non-cough sounds.</li>
</ul>
<h2 id="model-architecture">Model architecture</h2>
<p>The model architecture was optimized for:</p>
<ul>
<li>Small memory footprint<br />
</li>
<li>Low latency<br />
</li>
<li>Robustness to background noise<br />
</li>
<li>Reproducible performance under diverse conditions</li>
</ul>
<p>Hyperparameters were tuned through systematic experimentation, always
referencing the validation set—not the test set.</p>
<p>The algorithm was built specifically for deployment on a constrained
wearable device. This meant that the strict conditions had to be met in
regards to the following areas:</p>
<ul>
<li>Executed on the NRF52840 MCU<br />
</li>
<li>Real-time processing under Zephyr RTOS<br />
</li>
<li>Strict upper bounds on feature size, model size, and inference
latency<br />
</li>
<li>Efficient buffering and batching of audio frames<br />
</li>
<li>Energy Efficiency<br />
</li>
<li>Designed for continuous operation on battery power<br />
</li>
<li>Processing pipeline optimized to minimize wake cycles<br />
</li>
<li>Lightweight model architecture avoids expensive computations</li>
</ul>
<h2 id="privacy-by-design">Privacy by design</h2>
<p>The cough detection algorithm was developed using a strict
privacy-by-design approach in which the device never stores, transmits,
or makes accessible any raw audio. All sound captured by the microphone
is processed immediately through a lightweight feature-extraction
pipeline, and only the resulting cough/non-cough decision and timestamp
are retained. No audio files, waveforms, or spectral representations are
written to persistent storage, and no audio leaves the device at any
stage. This eliminates the possibility of reconstructing speech,
background conversations, or other sensitive sounds, protecting users
from inadvertent capture of personally identifiable information. By
architecting the system so that the algorithm’s inputs exist only
ephemerally and the outputs contain no acoustic content, Hyfe ensures
that continuous monitoring can occur safely in intimate, everyday
environments without compromising user privacy.</p>
<p>In the algorithm’s output:</p>
<ul>
<li>Only event timestamps are stored<br />
</li>
<li>No raw audio is saved or transmitted<br />
</li>
<li>On-device memory is limited to encrypted event logs</li>
</ul>
<h2 id="noise-handling-and-robustness-measures">Noise Handling and
Robustness Measures</h2>
<p>Real-world audio contains substantial variability. To address this,
the algorithm incorporates:</p>
<ul>
<li>Filters that suppress spectral patterns inconsistent with
coughs<br />
</li>
<li>Thresholding logic to avoid triggers during loud environmental
noise<br />
</li>
<li>Mechanisms that distinguish near-field from far-field events</li>
</ul>
<p>Training data was intentionally curated to include both challenging
and typical environments, enabling stronger generalization.</p>
<h2 id="adherence-to-industry-best-practices">Adherence to industry best
practices</h2>
<p>The development of the Hyfe cough detection algorithm followed widely
recognized industry best practices for machine learning systems
specifically, and software development more generally. These practices
emphasize reproducibility, transparency of development processes, data
governance, and robustness in real-world deployment. Hyfe adhered to
these principles in the following ways:</p>
<ol type="1">
<li>All data used for algorithm development was collected, labeled,
versioned,and stored under controlled procedures, ensuring traceability
and full auditability of the training corpus.<br />
</li>
<li>The algorithm was developed using strict separation of training,
validation, and hold-out test datasets, preventing data leakage and
guaranteeing unbiased model evaluation.<br />
</li>
<li>Hyfe followed best practices for documentation of model
architectures, preprocessing steps, feature definitions, and iterative
retraining, enabling reproducibility and controlled lifecycle
management.<br />
</li>
<li>The dataset was constructed to reflect the broad variability in user
demographics, environments, and cough types expected in the real world,
aligning with best practices for generalizability.<br />
</li>
<li>The model was designed and tested according to the principles of
reliable embedded ML deployment: resource-aware design, explainable
inference pathways, and deterministic behavior under constrained
hardware conditions.<br />
</li>
<li>Hyfe Inc. privacy-by-design principles, and risk-based development
considerations to ensure the algorithm behaves safely under
environmental unpredictability, individual diversity, and general
background noise.</li>
</ol>
<p>Collectively, these elements demonstrate alignment with modern
development frameworks such as human-centered design principles, edge-AI
safety guidelines, and emerging regulatory expectations for trustworthy
and transparent machine-learning systems.</p>
</body>
</html>
