<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>inter</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="../style.css" />
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="shortcut icon" href="/favicon.ico">

</head>
<body>
<h1 id="inter-and-intra-labeler-agreement">Inter and intra-labeler
agreement</h1>
<p>The reliability of any cough detection system hinges on the extent to
which the underlying biological phenomenon in question can be
accurately/objectively detected and quantified in the first place.
Accordingly, Hyfe has worked closely with external researchers to
quantify intra- and inter-labeler agreement in the labeling of
real-world cough sounds.</p>
<p>The results of these collaborations are below:</p>
<ul>
<li><a
href="https://www.nature.com/articles/s41598-025-85341-3">Chaccour, C.,
Sánchez-Olivieri, I., Siegel, S. et al. Validation and accuracy of the
Hyfe cough monitoring system: a multicenter clinical study. Sci Rep 15,
880 (2025). https://doi.org/10.1038/s41598-025-85341-3</a></li>
<li><a
href="https://bmjopenrespres.bmj.com/content/bmjresp/10/1/e001942.full.pdf">Sanchez-Olivieri
I, Rudd M, Gabaldon-Figueira JC, et al. Performance evaluation of human
cough annotators: optimal metrics and sex differences. BMJ Open Respir
Res 2023;10:e001942. doi:10.1136/ bmjresp-2023-001942</a></li>
</ul>
<p>In summary:</p>
<ul>
<li>Intra-labeler (intrarater) agreement was very high – e.g., Pearson’s
r ≈ 0.98. BMJ Open Respiratory Research</li>
<li>Inter-labeler (interrater) agreement was also high – e.g., Pearson’s
r ≈ 0.96.</li>
<li>Both studies demonstrate strong intrarater and interrater agreement
in cough-event annotation, supporting the reliability of the human
ground truth in Hyfe’s datasets.</li>
<li>Sánchez-Olivieri et al. clearly show that unit of analysis (cough
seconds vs cough counts) affects agreement, implying that the choice of
unit of analysis is an important methodological factor.</li>
<li>Together, the findings give confidence that the labelling protocols
used by Hyfe are reproducible and sufficiently consistent to support
high-quality algorithm training and validation workflows.</li>
</ul>
</body>
</html>
